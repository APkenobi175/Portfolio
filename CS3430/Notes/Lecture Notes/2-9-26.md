# CS3430 - Class 10 - 2/9/26 Notes

## Announcements

- We are gonna be talking about randomness today and probably wednesday as well.
- Do your homework bitches.

### Randomness

#### Why is randomness important?

- Randomness is important for a lot of reasons.
  - Randomized algorithms can be faster than deterministic algorithms.
  - Randomness is used in cryptography.
  - Randomness is used in machine learning.
  - Randomness is used in simulations.
  - Randomness is used in games.
  - Randomness is used in many other areas as well.
  - Password encryption, hashing, and many other things rely on randomness.

#### Random sequence

- A random sequence is a sequence of numbers that is generated by a random process.
- A random sequence is not necessarily random in the sense that it can be generated by a deterministic process, but it is random in the sense that it is unpredictable.
- A random sequence can be generated by a random number generator (RNG).
- A random sequence can be generated by a pseudo-random number generator (PRNG).
- A random sequence can be generated by a true random number generator (TRNG).

- True random isn't actually random. Its just unpredictable.
  - Use something unpredictable as a basis for randomness. in c++ you can use the time in seconds since the epoch (1/1/1970) as a seed for your random number generator. This is unpredictable because you don't know when the program will be run.

#### Randomness Tests

- You check a sequence of numbers, numbers in code, and get something called a test statistic.
- Then you compute probability, you get the P-value, and a math symbol called alpha, which is the threshold for rejecting the null hypothesis. $\alpha$
- you reject the null hypothesis, or you fail to reject the null hypothesis.
- This is from statistics!!!
  - Fail to reject means pass
  - Reject means fail

- If you fail to reject the null hypothesis, do not assume that the sequence is random. It just means that you don't have enough evidence to say that it is not random.

#### Basic Concepts and Vocabulary

- An Experiment
  - Consists of a sequence of trials.
- Random Variable
  - A variable, typically a capital $X$
  - Records the outcome of an experiment.
  - A random variable is a function that assigns a real number to each outcome of an experiment. (from a book called "Probability and Statistics for Computer Scientists" by Michael Baron)
  - There is a coresponding function to a random variable.
  - **A ledger of outcomes**
- Outcomes
  - $X:Outcomes \to \mathbb{R}$
  - $X$ is a function that takes an outcome and maps it to a real number
  - $X$ is a random variable that records the outcome of an experiment.
  - $\{H, T\} \to \{0, 1\}$
  - What happens in the real world while we are observing.

- Probability Measure
  - P: Takes the outcomes and assigns a probability to each outcome (between 0 and 1)
  - $P:Outcomes \to [0, 1]$
  - Example:
    - Experiment: Flipping a coin
    - Trial: Flip the coin once
    - Variable: $X:\{H,T\} \to \{1,0\}$
    - $P: \{H, T\} \to [0, 1]$
    - Probability Measure: $P(H) = 0.5$, $P(T) = 0.5$
    - $P(1) = P(0) = \frac{1}{2}$

- Randomness comes from the outcome, not from the expirement that the scientist invents.

- Question what is $P(X = x) = p^{x(1-p)^{(1-x)}}$? 
  - This is an expirement invented by Bernoulli. It is a coin flip expirement where the probability of heads is $p$ and the probability of tails is $1-p$. The random variable $X$ takes the value 1 if the outcome is heads and 0 if the outcome is tails. The probability measure assigns a probability to each outcome, which is $p$ for heads and $1-p$ for tails. The probability of getting $X = x$ is given by the formula $P(X = x) = p^{x}(1-p)^{(1-x)}$. This formula can be derived from the definition of a random variable and a probability measure.

- Why do you need to only give the probability of success?
  - Because the probability of failure is just 1 minute the probabability of success.

- Remember random variable is only applicable to a single trial.
- If 3 coin flips, there will be 3 random variables, one for each flip. $X_1, X_2, X_3$.

#### Mathematical Expectation

- $E[X_i] = $ Mathematical Expection
  - What we expect to see when we perform a single trial a very very large number of times
  - Like if we did many 3 coin flips, we would have a mathematical expectation for $X_1, X_2,$ and $X_3$.

  - Mathematical expectation is also defined in the scope of a single trial, not the entire experiment.

#### Examples

- Let's say $X$ is a random variable
- Outcomes are ${X_1, X_2, X_3, ... X_n}$
  - Next thing to define is the model (function)
- $P(X = x_i) = p_i$ for $p \in [0, 1]$
  - This is the probability measure, it assigns a probability to each outcome.
- $E[X] = \sum_{i=1}^{k} x_i p_i$
  - This is the weighted sum of the outcomes, where the weights are the probabilities of the outcomes.

### Lets roll a die

- Expirement: Rolling a fair die.

- Trial: One roll of the die.

- Outcomes: $X \to \{x_1 = 1, x_2 = 2, x_3 = 3, x_4 = 4, x_5 = 5, x_6 = 6\}$
- Model: $P(X = x_i) = \frac{1}{6}$
- $E[X] = \sum_{i=1}^{6} x_i p_i = \frac{1}{6}(1 + 2 + 3 + 4 + 5 + 6) = \frac{21}{6} = 3.5$

<div style="text-align: center; font-size: 60px; padding: 20px;">

 **MATH $\neq$ REALITY**

</div>

### Central Limit Theorem (CLT)

- $X_1, X_2, ... X_n$ are independent and identically distributed random variables with mean $\mu$ and variance $\sigma^2$.
- If I flip a coin, the probability of both heads and tails is $\frac{1}{2}$ from trial to trial. It won't change. So the random variables are identically distributed. And they are independent because the outcome of one flip doesn't affect the outcome of another flip.
- independant and identically distrubuted = i.i.d.
- In a video each frame would be an independant trial.
- 
- Lets say we have $E[X_i] = \mu \in \mathbb{R}$
- and $Var[X_i] = \sigma^2 \in \mathbb{R}$
  - Variance is the spread around the mean.
- Now we can form a sum $S_n = \sum_{i=1}^{n} X_i$
- We also have the Z statistic
  - $Z_n = \frac{S_n - E[S_n]}{\sigma \sqrt{Var(S_n)}}$
- $Z_n \approx N(0, 1)$
  - This means that z is approximately normally distrubuted with mean 0 and variance 1.

  - As you increase the number of trials, if the number of trials is really small then the hostgram looks like a uniform distrubution, the more trials you have the more triangular it looks, and if you increase even more you get a bell curve, which is a normal distribution.

- Do not confuse a trial and experiment.

- A sequence of trials is an experiment, but a trial is not an experiment. An experiment is a sequence of trials, and a trial is a single instance of an experiment. A trial can be repeated.

- And that brings us to the first test the monobit test.

### Monobit Test

- We will study 4 or 5 tests for randomness in this class, and the monobit test is the first one.

- Read the documentation for the assignment and make sure your technical analysis is correct. you GOT this.

#### Bit Sequences

- If you have a way to convert your data into bit sequences, consider the monobit test.
- Each bit in a sequence is independant of other bits (part of the null hypothesis) and each trial (each bit) is Bernoulli with parameter $p = \frac{1}{2}$ (part of the null hypothesis). So, flipping a coin would work.

- bits = $\{x_1, x_2, ... x_n\}$

- This means that the $Z_n$ statistic is approximately normally distrubuted $N(0, 1)$ under the null hypothesis.

- $S_n = \sum_{i=1}^{n} x_i$ Can we compute this directly. If you have 1000 bit sequence? Yes, this is computed from the input.

- $E[\sum_{i=1}^{n} x_i] = \sum_{i=1}^{n} E[x_i]$
  - This works because its always linear.

- Compute the expectation of the sum
  - $E[S_n] = \sum_{i=1}^{n} E[x_i] = \sum_{i=1}^{n} \frac{1}{2} = \frac{n}{2}$
  - Good job, now we can see that this is bernoulli because E is 1/2.

- BEcause its bernoulli, we can compute the variance of the sum.
  - $Var[x] = p(1-p) = \frac{1}{4}$

- Since we are assuming they are independant trials the variance of the sum is the sum of the variances.
  - $Var[S_n] = \sum_{i=1}^{n} Var[x_i] = \sum_{i=1}^{n} \frac{1}{4} = \frac{n}{4}$

- $Z_n$ for the monobit test = $\frac{S_n - E[S_n]}{\sqrt{Var[S_n]}}$
  - $Z_n = \frac{S_n - \frac{n}{2}}{\sqrt{\frac{n}{4}}}$
- n = length of the bit sequence.

---

### Monobit Test in Python

- There are liraries that can do this for you in python. YOu give a function a statistic and it gives you a p-value.

- $\alpha = 0.05$ is default

- IF:
  - p-value < $\alpha$ then we reject the null hypothesis and say that the sequence is not random, does not ABSOLUTELY MEAN that the sequence is not random.
  - p-value >= $\alpha$ then we fail to reject the null hypothesis and say that we don't have enough evidence to say that the sequence is not random.
