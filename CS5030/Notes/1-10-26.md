# CS5030 – Parallelism, Load Balancing, and Scheduling (What I Learned)

## 1. Why Parallelism Matters

Historically, performance improvements came from increasing clock speeds as transistor density increased (Moore’s Law). However, higher clock speeds led to increased power consumption, excess heat, and reliability issues. Around 2005, clock speeds plateaued due to these physical limitations.

To continue improving performance, systems shifted toward using **multiple cores** instead of faster single cores. As a result, programmers must explicitly write **parallel programs** to benefit from modern hardware. Serial programs do not automatically gain performance improvements.

---

## 2. Parallelism Concepts

### Task Parallelism

Task parallelism occurs when independent tasks are executed simultaneously by different cores.

**Pizza Party Example:**
- Ordering pizzas  
- Setting up tables  
- Setting up chairs  
- Ensuring no pizza has fruit on it  
- Getting eating utensils  

Each task is independent and can be completed concurrently by different students (cores), reducing overall completion time.

---

### Data / Work Partitioning

Data parallelism (or work partitioning) occurs when the same overall task is divided into smaller pieces and distributed across multiple cores.

**Cleaning Example:**
- One student throws away pizza boxes  
- One student sweeps the floor  
- One student puts tables and chairs away  

Each student works on a different portion of the same task at the same time.

---

## 3. Load Balancing

Load balancing means distributing work evenly among cores so that no single core becomes a bottleneck. The overall performance of a parallel program is limited by the slowest (most heavily loaded) core.

Naively dividing work into equal chunks can result in imbalance when tasks have different execution times.

---

## 4. Motivating Example: Uneven Loop Workloads

Consider a loop with:
- `n = 15` iterations  
- `p = 3` cores  

Iteration `i` takes `i` milliseconds.

Total work:
```
1 + 2 + 3 + ... + 15 = 120 ms
```

Naive block assignment:
- Core 0: iterations 1–5 → 15 ms  
- Core 1: iterations 6–10 → 40 ms  
- Core 2: iterations 11–15 → 65 ms  

Parallel runtime = **65 ms**, since the slowest core determines completion time.

---

## 5. Dynamic Load Balancing Strategy

To reduce imbalance, iterations should be assigned dynamically rather than in fixed blocks.

**Key idea:**
> Assign the next iteration to the core with the least current workload.

This mixes expensive and inexpensive iterations across cores and keeps all cores busy.

---

## 6. Pseudocode for Load-Balanced Scheduling

```text
Algorithm BalanceLoad(n, p):
    time[0..p-1] = 0
    iters[0..p-1] = empty lists

    for i = n down to 1:
        min_core = 0
        for c = 1 to p-1:
            if time[c] < time[min_core]:
                min_core = c

        append i to iters[min_core]
        time[min_core] = time[min_core] + i

    return time, iters
```

---

## 7. Numerical Example (n = 15, p = 3)

One valid balanced result:

- Core 0: time = 41 → [15, 10, 9, 4, 3]  
- Core 1: time = 40 → [14, 11, 8, 5, 2]  
- Core 2: time = 39 → [13, 12, 7, 6, 1]  

Parallel runtime (makespan) = **41 ms**, a significant improvement over 65 ms.

---

## 8. Combination Pizza Analogy with Load Balancing

Tasks for the pizza party are assigned dynamically to the student with the lightest workload. If a student has no tasks, they receive the next task. If all students are busy, the next task is assigned to the student whose current tasks take the least time.

This approach balances the workload so all students finish at roughly the same time, directly mirroring dynamic load balancing in parallel computing.

---

## 9. C++ Concepts Learned

- `std::vector` is the C++ equivalent of a Python list.
- `std::vector<std::vector<int>>` represents a list of lists.
- `push_back()` is equivalent to Python’s `append()`.
- Loop bounds must avoid assigning iteration `0` when costs start at `1`.
- Finding the least-loaded core can be done with a simple loop or `std::min_element`.

- My C++ Code for Assignment 1.2:

```c++
#include <iostream>
#include <vector>
#include <algorithm>
#include <numeric>

int main(){
    int n = 15;
    int p = 3;

    // Total time on each core
    std::vector<int> time(p,0); // this creates a vector of size p with all 0s named time

    // COmpile a list of iterations for each core (list of lists)
    std::vector<std::vector<int>>iterations(p); // this creates a vector of size p with empty vectors inside named iterations 

    // Now that we have out data structures we can start assigning iterations to cores

    for(int i = n; i == 1; i--){
        // find core with minimum time
        int min_core = std::min_element(time.begin(), time.end()) - time.begin();

        // assign iteration i to min_core
        iterations[min_core].push_back(i);

        // update time for min_core
        time[min_core] += i;


    }

    // Print out the assignments
    for (int core = 0; core<p; core++){ // loop starting at core =0 while core is less than p
        std::cout << "Core " << core << ": (time = " << time[core] << ") " ;
        for (int it : iterations[core]){ // range based for loop
            std::cout << it << " ";
        
        }
        std::cout << std::endl;
    }
    

}
```

