# CS5030 Class 2 - 1/7/25 Notes

## Announcements

* GGJ26 video game at library. Friday and Saturday 1/30-1/31
* Free food
* Not going..

## Review

1. What is a variable?
    * Data stored in memory
2. What determines how much memory a variable takes up?
    * Its type
      * int - 32 bits/4 bytes, signed integer
      * `int a` - declares a variable a of type int
3. What is a pointer variable?
    * A variable that stores the memory address of another variable - 32 or 64 bits depending on architecture
        * `int* p` - declares a pointer variable p of type int*
        * the `*` indicates that it is storing an address of an integer
        * why do we care? Because we want to keep track of what we can find at that address, in this case an integer
    * Some C APIs use `void*` - a pointer to an unknown type
      * When this happens you will need to cast it to the correct type before dereferencing it
4. What is dereferencing a pointer?
    * Accessing the address pointed to by p, we would use &p to get the address of p, and `*p` to get the value at that address
5. What does *p mean?
    * The value that is contained at the address stored in p ( an integer in this case)
6. What does &p mean?
    * The address of the variable p itself

### C++ and C syntax for pointers

```cpp
#include <iostream>

using namespace std;

int main(){
    int var = 20; // actual variable declaration
    int *ip;    // pointer variable

    ip = &var; // store the address of var in pointer variable ip
    cout << "Value of var variable: ";
    cout << var << endl; // This prints 20

    // print the address stored in ip pointer variable
    cout << "Address stored in ip variable: ";
    cout << ip << endl; // This prints the address of var
    // access the value at the address stored in ip
    cout << "Value of *ip variable: ";
    cout << *ip << endl; // This prints 20

    //int a[10]; // declare an array of 10 integers version 1
    int* a = (int*)malloc(10 * sizeof(int)); // allocate memory for 10 integers vversion 2
    cout << a << " , " << &a << " , " << &a[0] << endl; // This will first print the address of the array, and so will the second and third
    return 0;
}
```

* The last line shows that:
  * When you define an array the value of the array is basically a pointer to the first element of the array.
  * so `a` is equivalent to `&a[0]`
  * `&a` is also the same address, but its type is different. `&a` is of type `int (*)[10]` - pointer to an array of 10 integers, while `a` and `&a[0]` are of type `int*` - pointer to an integer.
* In version 2 the second &a will be different because we allocated memory for the array on the heap, so the address of a is different from the address of the first element of the array.
* You prolly won't have to look at pointers of pointers. so don't worry about it.

* Malluc allocates memory on the heap, so you have to free it when you're done with it.


### Compilation Process

1. Proprocessor: Expand code in the source files (.c, .cpp)
2. Compiler: converts the exapnded code into assembly code (.obj)
3. Assembler: created object code (incomplete binary code) using the assembly code (.lib, .o, .a), this is where functions from libraries are put in
4. Linker: combines object codes and libraries into the final executable (.exe, .out, etc) 

>[Note!] You can get errors at any of these stages.

### Memory layout of a C program

1. Text: executable instructions
2. Initialized data: global and static variables
3. Uninitialized data: global and static not initialized variables
4. Stack: in a stack frame are stored local variables and function pointers
5. Heap and free store: dynamic memory allocation

* Be very vareful declaring large arrays, they can overflow the stack and crash your program, which is bad.
* These start at low addresses and end at high addresses.

### Memory Management

* What you allocate with new you deallocate with delete
* What you allocate with malloc you deallocate with free

### More C Syntax:

* Access a variable in structure b with `b->var` if b is a pointer to the structure
* What is a structure?
  * A user-defined data type that groups related variables of different types
  * Like creating a user defined tag in PLC programming or a class in python

## Parallel Architectures

### The Von Neumann Architecture

* Memory and CPU with interconnection in between
* Data and execution state are stored in (very fast) registers inside the CPU, ALU registers, and Control registers.

* Central Processing Unit (CPU)
  * Control Unit (CU): Determines what to do next
  * Arithmetic Logic Unit (ALU): Does arithmetic and logic operations

### Type of parallel systems

* Shared-memory
  * The cores can share access to the computers memory
  * Coordinates the cores by having them examind and update shared memory locations

* Distributed-memory
  * Each core has its own privaete memory
  * The cores must communicate explicityly by sending messages across a network via the shared-memory system

### Vocab

* Register - very fast storage, apart of the CPU
* Program Counter - stores address of the next instruction to be executed
* Bus - wires and hardware that connects the CPU and memory

### Instance of OS process

1. The executable machine language program
2. A block of memory executable code, call stack, heap
3. Descriptors of resources the os has allocated to the process
4. Security information (which resources the process can access)
5. Information about the state of the process (registers, running state, etc)

### Multitasking

* Gives the illusion that a single processor system is running multiple programs simultaneously
* The OS allocates time slices to each process, switching between them rapidly

### Threads

* Threads are contained within processes
* They allow programmers to divide their programs into more or less independant tasks
* The hope is that when on thread blocks because it is waiting on a resource, another will have work to do and can run.
* **Forking** is when the process master thread creates a new thread.
* **Joining** is when a thread waits for another thread to finish before continuing, and joins back with it.
* Threads are your parallel tasks

### Von Neumann Bottleneck

* The speed of the CPU is limited by the speed of memory access
* Analogy: If products are manufactured at a higher rate than the raw materials can be supplied, the production line will stall waiting for more materials to arrive.
* That is not very good lean manufacturing (autoliv reference)

## Introduction to Cache (memory, not cache valley)

* Principle of locality:
  * Accesses one location is followed by accesses to nearby locations
  * **Spacial locality**: accessing data locations near one another
  * **Temporal locality**: accessing the same data in the near future

### Principle of locality

```cpp
  float z[1000];
  sum = 0.0;
  for (i = 0; i < 1000; i++) {
        sum += z[i]; // accessing data locations near one another - spacial locality
  }

```

* Cache is accessed in blocks ( or cache lines)
* Cache blocks are 8-16 times bigger than memory locations
* When reading one entry of an array we are actually fetching 8-16 values in the cache

### Issues with Cache

* 