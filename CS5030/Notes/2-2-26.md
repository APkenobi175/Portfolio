# CS5030 - Class 8 - 2/2/26 Notes

## Announcements

- Homework 2 is due on friday, I am mostly done with it.

## Review of Last Class

- I fucking hate this class its worse than cs2420 data structures and algorithms lol
- Last class we talked about mutexes and how they can be used to execute a critical section safely. We also talked about barriers, and avoiding race conditions, which is when multiple threads access shared data at the same time and cause incorrect results.
- We also talked about semaphores, which are another way. They are a variable that can allow multiple threads to access a shared resource up to a certain limit (num threads). Semaphores can be used to implement producer-consumer problems, where one thread produces data and another thread consumes it.

- What are barriers useful for?
- Barriers are useful for synchronizing threads at certain points in the program. They ensure that all threads reach a certain point before any thread can proceed. This is useful when threads need to wait for each other to complete a task before moving on to the next task.
- Good for computing slowest thread.
- Good for debugging.

- Also talked about condition variables, which are used to signal between threads. They allow one thread to wait for a condition to be met before proceeding. This is useful when one thread needs to wait for another thread to complete a task before continuing.

## Controlling access to a large shared data structure

> HINT: Study the ATM example, and try to implement it yourself.
> This can save a lot of time when trying to do your homework.

> Review linked lists and arrays in C++

- Supposed a shared data structure is a sorted linked list of ints. and the operations of interest are member, insert, and delete.

- Array -> Continuous chunk of memory
  - Problem with arrays: resizing is expensive, keeping arrays sorted is expensive, inserting and deleting is expensive, searching is okay (binary search is O(log n))

- Linked List -> Nodes with pointers to next node
  - Kind of the opposite problem
  - Data can be inserted and deleted easily. 
  - Its just an array where each element points to the next or previous element.
  - Search is slow because you have to go element by element (O(n))

- how to create a linked list in C/C++?

```c
struct list_node {
    int data;
    struct list_node* next; // pointer to next node
};
```

- Searching a sorted linked list for a value

```cpp

// FINDING A VALUE IN A SORTED LINKED LIST
int Member(int value, struct list_node* head_p){
    struct list_node* curr_p = head_p; // this line initializes a pointer to the head of the list 
    while (curr_p != NULL && curr_p->data < value){ // loop until we find the value or reach the end of the list

        curr_p = curr_p->next;
    }
    if (curr_p != NULL && curr_p->data == value){
        return 1; // found
    } else {
        return 0; // not found
    }
}
```

- Why do we call it Member and not Search?
- Because it returns whether the value is a member of the list or not.
- this is stupid
- This professor is a try hard and wants to use fancy terminology for everything.
- He also wants to make things more complicated than they need to be.
- But then again ive never used c before so maybe this is normal for c programmers.

- You need to understand this code, but the juice is to find a member in a sorted linked list you need to go through the list until you find the value that is beyond the value you are looking for, or you find the value itself, or you reach the end of the list.

- Inserting a value into a sorted linked list

- You traverse the list until you find the spot before and after where the new value should go, then you create the new node, and then update the pointers of those nodes to point to the new node.

- e.g if I insert 7 i place it between 5 and 8, and I adjust 5 pointers to point to 7, and 7 points to 8.

```cpp


int insert(int value, struct list_node** head_p){
    struct list_node* curr_p = *head_p; // pointer to current node
    struct list_node* prev_p = NULL; // pointer to previous node
    struct list_node* temp_p; // pointer to new node

    // curr_p starts at head of list
    // Then it goes to the next node.
    // next is defined in the struct as a pointer to the next node.
    // so when we use -> we are accessing the member of the struct that the pointer points to, which is the next node.
// INSERTING A VALUE INTO A SORTED LINKED LIST
while (curr_p != NULL && curr_p->data < value){
    prev_p = curr_p;
    curr_p = curr_p->next;
}
if (curr_p == NULL || curr_p->data > value){ // value not in list
    temp_p = malloc(sizeof(struct list_node));
    temp_p->data = value;
    temp_p->next = curr_p;
    if (prev_p == NULL){ // insert at head
        head_p = temp_p;
    } else {
        prev_p->next = temp_p;
    }
    return 1; // success
} else {
    return 0; // value already in list
}
```

- Can a linked list have duplicate values?
- No, in this example we do not allow duplicate values.
- But you could modify the code to allow duplicates if you wanted to.
- Traditionally linked lists do not allow duplicates.
- what does -> mean in C/C++?
- It is used to access members of a struct through a pointer.
- So, in this example:
  - temp_p->data means access the data member of the struct that temp_p points to and temp_p->next means access the next member of the struct that temp_p points to.
- instead of using -> you could use (*temp_p).data but that is more cumbersome.


- Deleting a value from a sorted linked list

  - First you have to find where the node you want to delete is.
  - Then, you delete it by using free() to free the memory allocated for that node.
  - then update the pointers of the previous node to point to the next node.

```cpp
// DELETING A VALUE FROM A SORTED LINKED LIST
int delete(int value, struct list_node** head_p){
    struct list_node* curr_p = *head_p; // pointer to current node
    struct list_node* prev_p = NULL; // pointer to previous node

    while (curr_p != NULL && curr_p->data < value){
        prev_p = curr_p;
        curr_p = curr_p->next;
    }
    if (curr_p != NULL && curr_p->data == value){ // value found
        if (prev_p == NULL){ // delete head
            *head_p = curr_p->next;
        } else {
            prev_p->next = curr_p->next;
        }
        free(curr_p); // free memory
        return 1; // success
    } else {
        return 0; // value not found
    }
}
```

- list_node* is the pointer to the struct list_node
- so when we define our curr_p variable we are declaring it as a pointer to a struct list_node
- Why pointer and not just struct list_node?
- Because we want to be able to traverse the linked list, and we need to be able to point to the next node in the list.
- If we just used struct list_node, we would be copying the entire struct each time we wanted to move to the next node, which is inefficient.
- By using pointers, we can just change the pointer to point to the next node, which is much more efficient.

### Multithreaded Linked List

- In order to share access to the list we can define head_p to be a global variable.

- this will simplify the function headers for Member, Insert, and Delete because we no longer need to pass in head_p as a parameter, because all the threads can access the global variable.

- Problems:
  - Some threads could be deleting an element, and other threads might think it still exists.
  - This is due to how many pointer operations are being done.

- Solution:
  - Use a mutex to protect the entire linked list.
  - If you are changing your data structure, do it in a way that all the threads that are working on part of the data structure see all the same changes and everything is consistent.

- For arrays, we were synchronizing before and after we updated the array.

- Let's approach the problem the same way for linked lists.

  - lock the list any time that a thread attempts to access it for any reason (member, insert, delete).

```c
pthread_mutex_lock(&list_mutex);
// critical section
Member(value);
pthread_mutex_unlock(&list_mutex);
```

- Issues with this:

  - We are seralizing access to the list
  - If the vast majorit of our operations are calls to member we fail to exploit this opportunity for parallelism.

  - On the other hand if most of our operations are insert and delete then this is probably the best we can do.

  - THis is because insert and delete modify the list, so we have to lock the entire list before doing so.

- Can we do better for member operations?

  - Yes, instead of locking the entire list, we can lock each node as we traverse the list.

```cpp
struct list_node_s{
    int data;
    struct list_node_s* next;
    pthread_mutex_t node_mutex; // mutex for this node
}
```

- This adds a mutex to each node in the list.

- Problems with this approach:

  - Deadlock can occur if two threads try to lock the same nodes in different orders.

  - For example, thread A locks node 1 and then tries to lock node 2, while thread B locks node 2 and then tries to lock node 1. This creates a circular wait condition, leading to deadlock.

  - increase of storage space and complexity of code.

```c
int Member(int value){
    struct list_node* temp_p;

    pthread_mutex_lock(&head_p->node_mutex);
    temp_p = head_p;
    while (temp_p != NULL && temp_p->data < value){
        if (temp_p->next != NULL){
            pthread_mutex_lock(&temp_p->next->node_mutex);
        }
        if (temp_p == head_p){
            pthread_mutex_unlock(&head_p->node_mutex);
        }
        temp_p = temp_p->next;
    }
    return 0;
}
```

- There is a solution to avoid deadlock here.

- Neither of our multithreaded link lists exploits the potential for simultaneous access to any node by threads that are executing member operations.

### Pthreads Read-Write Locks

- Provides two lock functions
  - The first lock function locks the read-write lock for reading
  - The second lock function locks the read-write lock for writing
  - This way one thread can write to the data structure while multiple threads can read from it simultaneously.

- If any threads own the lock for reading, any threads that want to write have to wait until all the readers are done.

```c
pthread_rwlock_rdlock(&rwlock); // lock for reading
Member(value);
pthread_rwlock_unlock(&rwlock); // unlock
pthread_rwlock_wrlock(&rwlock); // lock for writing
Insert(value);
pthread_rwlock_unlock(&rwlock); // unlock
```

- We are read write locking the entire list here, but we could also do it on a per node basis like we did with mutexes. but THAT would be more complicated.

- Advantage of this:
  - It doesn't make slower operations that are already slow.
  - It makes faster operations faster.
  - It reduces contention for the lock, allowing for more parallelism.
  - It makes operations that are writing safer because they have exclusive access to the data structure.


#### Which of our methods performs best?

- Read-Write locks perform best when the majority of operations are reads (member operations).
- One mutex for entire list performs better than one mutex per node, but it gets worse with more threads.
- One mutex per node is BAD because of deadlock and complexity.

- Read-Write locks shine above all because they can be done at the same time

- this is ideal if you have a LOT OF MEMBER OPERATIONS compared to insert and delete operations.

- Remember Read/Write to be a MEMBER of the cool kids club. Read/Write is better for MEMBER operations.
  - This is because member operations are read operations
  - And write operations will block read operations.

- if you have 99% write operations is it better to leave it serialzed?
  - yeah

### Thread Safety

- a block of code is thread-safe if it can be simultaneously executed by multiple threads without causing any problems. The results are what we expect.

- Suppose we want to use multiple threads to tokenize a file that consists of ordinary english text.

- The tokens are just contiguous sequence of characters seperated from the rest of the text by white space, a space, tab, or newline.

- Simple approach:

  - divide file into lines of text and assign the lines to the threads in a round robin fashion.
  - We can serialize access to the lines of input using semaphores or mutexes.
  - After a thread has a single line of input, it can tokenize the line using the strtok function from the C standard library.

  - The first time its called the string argument should be the text to be tokenized
    - our line of input

  - for subsequent calls the string argument should be NULL
    - this tells strtok to continue tokenizing the same string

```c
char* strtok(char* str, const char* seperators);
```

- Syntax explained
  - char* str: pointer to the string to be tokenized
  - const char* seperators: pointer to a string containing the seperator characters

- A while loop will run the strtok function until it returns null, indicating that there are no more tokens.

- What can go wrong?
  - strtok uses static storage to keep track of its position in the string between calls.
  - This cache string is shared by all threads, not private to each thread.
  - strtok was written for single threaded programs.
  - some words will be incorrect, and its not about the order of execution.

  - If two threads call strtok on the same string at the same time, they will interfere with each other and produce incorrect results.


- **STRTOK IS NOT THREAD SAFE**


- Other unsafe C library functions:
  - random in stdlib.h
  - asctime in time.h


- However, there is a strtok_r function that is thread safe.
- It has another parameter that saves the pointer to the current position in the string between calls.

- what does ** mean? pointer to a pointer?
  - Yes, it is a pointer to a pointer.
  - This is used to allow the function to modify the pointer that is passed in.


